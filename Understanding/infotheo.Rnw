\chapter{Information-Theoretic Measures}
\label{chap:info-theo}
\lettrine{E}{ntropy} over music features is considered here as a metric for characterising users' music listening behaviour. This measure can be used to produce time-series analyses of user behaviour, allowing for the identification of events where this behaviour changed. In a case study, the date when a user adopted a different music retrieval system is detected. These detailed analyses of listening behaviour can support user studies or provide implicit relevance feedback to music retrieval. More broad analyses are performed across the \Sexpr{prettyPrint(playlist_count$COUNT)} playlists. A Mutual Information based feature selection algorithm is employed to identify music features relevant to how users create playlists. This user-centred feature selection can sanity-check the choice of features in MIR. The information-theoretic approach introduced here is applicable to any discretisable feature set and distinct in being based solely upon actual user behaviour rather than assumed ground-truth. The techniques described here are developed to support MIR researchers in performing quantitative yet user-centred evaluations of their music features and retrieval systems.
\newpage

<<child-demo, child='listeninghistory.Rnw'>>=
@

<<child-demo, child='playlists.Rnw'>>=
@

\newpage
\section{Conclusions}
This chapter has proposed the use of information-theoretic measures to capture users' music-listening behaviour and relate it to an arbitrary feature set. Some example applications were presented, including an analysis of a user's listening history in terms of changes in the music features, and identifying the degree to which music features shared information with the way users organised playlists. These approaches are highly generalisable, any clustering could be investigated instead of playlist membership, for example the time of day or location of track plays. An interactive example of \figref{fig:listens-historyplot}, where parameters such as window size can be changed, is available along with the corresponding code.\footnote{http://www.dannyboland.com/spud/}

The measures proposed in this chapter must still be interpreted in the context of a user-centred evaluation. Change-points in the entropy of a user's music listening can identify important events to lead discussions with users, however would be difficult to interpret by themselves. Using relative entropy can go some way towards accounting for the differing nature of users' music collections. In the playlist example, there is a question as to what the Adjusted Mutual Information should be calculated in relation to. Showing AMI relative to to the feature entropy is an intuitive way to present the amount of shared information. It is usual and typically more appropriate, however, to calculate AMI relative to the maximum of either the class or feature entropy. The distinction is whether a feature capturing relatively few bits of information should be ranked highly if all of that information is explained by playlist membership.

While the features are described as being from Syntonetic and Spotify, further information regarding the features is limited due to commercial sensitivity. The choice of features is such that they are high-level and intuitive, serving as placeholder examples which can be substituted with other music features. The use of commercially-derived features is because of licensing issues with large music collections.

Measuring the information content of a retrieval interaction provides a quantitative grounding to the idea of \emph{retrieval control}. As discussed in \chapref{chap:eng}, the reduction of entropy from an overall music collection in making a selection gives a measure of how controlled the selection was. Making the distinction about whether the bits of information were provided by the user or an autonomous recommender system can represent the handover of control. These ideas are applied in the evaluation of the commercial BeoSound Moment product in \chapref{chap:industrial}, capturing the entropy of recommendations designed to match user engagement. 
\newpage